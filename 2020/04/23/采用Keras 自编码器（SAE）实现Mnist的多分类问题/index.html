<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>堆栈式自编码器 | 一碗竹叶青</title><meta name="description" content="堆栈式自编码器"><meta name="keywords" content="DNN,Keras"><meta name="author" content="julianxu"><meta name="copyright" content="julianxu"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="堆栈式自编码器"><meta name="twitter:description" content="堆栈式自编码器"><meta name="twitter:image" content="http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190502/3a0df3c1cd0a48d6abb30bc0e3698fe0.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="堆栈式自编码器"><meta property="og:url" content="http://snail110.github.io/2020/04/23/%E9%87%87%E7%94%A8Keras%20%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88SAE%EF%BC%89%E5%AE%9E%E7%8E%B0Mnist%E7%9A%84%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"><meta property="og:site_name" content="一碗竹叶青"><meta property="og:description" content="堆栈式自编码器"><meta property="og:image" content="http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190502/3a0df3c1cd0a48d6abb30bc0e3698fe0.jpeg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://snail110.github.io/2020/04/23/%E9%87%87%E7%94%A8Keras%20%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88SAE%EF%BC%89%E5%AE%9E%E7%8E%B0Mnist%E7%9A%84%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"><link rel="prev" title="linux安装anaconda" href="http://snail110.github.io/2020/04/23/Linux%E5%AE%89%E8%A3%85%20Anaconda%E3%80%81Tensorflow-GPU%E3%80%81Keras%E3%80%81pytorch-gpu%E8%BF%87%E7%A8%8B/"><link rel="next" title="Wide&amp;Deep" href="http://snail110.github.io/2020/04/23/Wide&amp;Deep%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5/js/md5.min.js"></script><script src="https://tajs.qq.com/stats?sId=66547258" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/user.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 档案室</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/playlist/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-mnist的读取"><span class="toc-number">1.</span> <span class="toc-text">1.mnist的读取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-数据预处理"><span class="toc-number">2.</span> <span class="toc-text">2.数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-模型训练"><span class="toc-number">3.</span> <span class="toc-text">3.模型训练</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190502/3a0df3c1cd0a48d6abb30bc0e3698fe0.jpeg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">一碗竹叶青</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 档案室</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/playlist/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">堆栈式自编码器</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-23 08:56:23"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-23</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-04-23 09:15:33"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-04-23</span></time></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/23/%E9%87%87%E7%94%A8Keras%20%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88SAE%EF%BC%89%E5%AE%9E%E7%8E%B0Mnist%E7%9A%84%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><meta name="referrer" content="no-referrer">

<p>堆栈式自编码器的原理请看：<br><a href="https://blog.csdn.net/hjimce/article/details/49106869" target="_blank" rel="noopener">https://blog.csdn.net/hjimce/article/details/49106869</a><br>这里直接进行代码的实现<br>代码结构分为：1.mnist的读取，2.数据预处理，3.模型的训练过程。</p>
<h2 id="1-mnist的读取"><a href="#1-mnist的读取" class="headerlink" title="1.mnist的读取"></a>1.mnist的读取</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">&#39;&#39;&#39; 采用keras的堆栈式Autoencode 将mnist的图片进行分类&#39;&#39;&#39;</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import struct</span><br><span class="line">np.random.seed(2018)</span><br><span class="line"></span><br><span class="line">from keras.datasets import mnist</span><br><span class="line">from keras.models import Model</span><br><span class="line">from keras.layers import Dense,Input</span><br><span class="line">from keras.utils.np_utils import to_categorical</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># 训练集 shape (60,000,28*28) 测试集 shape (10000,)</span><br><span class="line">def load_mnist(path,kind&#x3D;&#39;train&#39;):</span><br><span class="line">    &#39;&#39;&#39; load MNIST data from path&#39;&#39;&#39;</span><br><span class="line">    labels_path&#x3D;os.path.join(path,&#39;%s-labels.idx1-ubyte&#39; % kind)</span><br><span class="line">    images_path&#x3D;os.path.join(path,&#39;%s-images.idx3-ubyte&#39; % kind)</span><br><span class="line"></span><br><span class="line">    with open(labels_path,&#39;rb&#39;) as lbpath:</span><br><span class="line">        magic,n&#x3D;struct.unpack(&#39;&gt;II&#39;,lbpath.read(8))</span><br><span class="line">        labels&#x3D;np.fromfile(lbpath,dtype&#x3D;np.uint8)</span><br><span class="line">    with open(images_path,&#39;rb&#39;) as impath:</span><br><span class="line">        magic,num,rows,cols&#x3D;struct.unpack(&#39;&gt;IIII&#39;,impath.read(16))</span><br><span class="line">        images&#x3D;np.fromfile(impath,dtype&#x3D;np.uint8).reshape(len(labels),784)</span><br><span class="line">    return images,labels</span><br><span class="line"></span><br><span class="line">X_train,y_train&#x3D;load_mnist(&#39;F:\pycharm\MNIST_dataset&#39;,&#39;train&#39;)</span><br><span class="line">X_test,y_test&#x3D;load_mnist(&#39;F:\pycharm\MNIST_dataset&#39;,&#39;test&#39;)</span><br><span class="line">y_train_cate&#x3D; to_categorical(y_train, num_classes&#x3D;10)</span><br><span class="line">y_test_cate&#x3D; to_categorical(y_test, num_classes&#x3D;10)</span><br><span class="line"></span><br><span class="line"># 显示mnist图片</span><br><span class="line"># 图形2*5 灰度值</span><br><span class="line">fig,ax&#x3D;plt.subplots(nrows&#x3D;2,ncols&#x3D;5,sharex&#x3D;True,sharey&#x3D;True)</span><br><span class="line">ax&#x3D;ax.flatten()</span><br><span class="line">for i in range(10):</span><br><span class="line">    img&#x3D;X_train[y_train&#x3D;&#x3D;i][1].reshape(28,28)</span><br><span class="line">    ax[i].imshow(img,cmap&#x3D;&#39;Greys&#39;,interpolation&#x3D;&#39;nearest&#39;)</span><br><span class="line"></span><br><span class="line">ax[0].set_xticks([])</span><br><span class="line">ax[0].set_yticks([])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>当然也可以直接采用keras中的函数 mnist.load_data()获取数据，但是由于数据量比较大，有可能直接下载不成功，所以我们直接采用将数据下载到本地文件夹中，然后再进行读取。数据下载链接：<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a><br>在数据读取过程中，需要特别注意的地方数据格式是idx1-ubyte，idx3-ubyte的格式，需要进行转换。<br>详细解释代码：<br>load_mnist 函数返回两个数组, 第一个是一个 n x m 维的 NumPy array(images), 这里的 n 是样本数(行数), m 是特征数(列数). 训练数据集包含 60,000 个样本, 测试数据集包含 10,000 样本. 在 MNIST 数据集中的每张图片由 28 x 28 个像素点构成, 每个像素点用一个灰度值表示. 在这里, 我们将 28 x 28 的像素展开为一个一维的行向量, 这些行向量就是图片数组里的行(每行 784 个值, 或者说每行就是代表了一张图片). load_mnist 函数返回的第二个数组(labels) 包含了相应的目标变量, 也就是手写数字的类标签(整数 0-9).<br>为了理解这两行代码, 我们先来看一下 MNIST 网站上对数据集的介绍:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">TRAINING SET LABEL FILE (train-labels-idx1-ubyte):</span><br><span class="line"></span><br><span class="line">[offset] [type]          [value]          [description] </span><br><span class="line">0000     32 bit integer  0x00000801(2049) magic number (MSB first) </span><br><span class="line">0004     32 bit integer  60000            number of items </span><br><span class="line">0008     unsigned byte   ??               label </span><br><span class="line">0009     unsigned byte   ??               label </span><br><span class="line">........ </span><br><span class="line">xxxx     unsigned byte   ??               label</span><br><span class="line">The labels values are 0 to 9.</span><br></pre></td></tr></table></figure>
<p>通过使用上面两行代码, 我们首先读入 magic number, 它是一个文件协议的描述, 也是在我们调用 fromfile 方法将字节读入 NumPy array 之前在文件缓冲中的 item 数(n). 作为参数值传入 struct.unpack 的 &gt;II 有两个部分:</p>
<blockquote>
<p>: 这是指大端(用来定义字节是如何存储的); 如果你还不知道什么是大端和小端, Endianness 是一个非常好的解释. (关于大小端, 更多内容可见&lt;&lt;深入理解计算机系统 – 2.1 节信息存储&gt;&gt;)<br>I: 这是指一个无符号整数.<br>通过执行下面的代码, 我们将会从刚刚解压 MNIST 数据集后的 mnist 目录下加载 60,000 个训练样本和 10,000 个测试样本.</p>
</blockquote>
<p>为了了解 MNIST 中的图片看起来到底是个啥, 让我们来对它们进行可视化处理. 从 feature matrix 中将 784-像素值 的向量 reshape 为之前的 28*28 的形状, 然后通过 matplotlib 的 imshow 函数进行绘制。</p>
<h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2.数据预处理"></a>2.数据预处理</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 数据预处理</span><br><span class="line">X_train&#x3D;X_train.astype(&#39;float32&#39;)&#x2F;255-0.5 # minmax_normalized(归一化在（-0.5,0.5）)之间</span><br><span class="line">X_test&#x3D;X_test.astype(&#39;float32&#39;)&#x2F;255-0.5 # minmax_normalized</span><br><span class="line">X_train_len&#x3D;X_train.shape[0]</span><br><span class="line">X_test_len&#x3D;X_test.shape[0]</span><br><span class="line"></span><br><span class="line">X_train&#x3D;X_train.reshape((X_train_len,-1))</span><br><span class="line">X_test&#x3D;X_test.reshape((X_test_len,-1))</span><br><span class="line"></span><br><span class="line">print(X_train.shape,X_test.shape)</span><br></pre></td></tr></table></figure>
<p>主要是将灰度图像值进行（-0.5,0。5）的归一化</p>
<h2 id="3-模型训练"><a href="#3-模型训练" class="headerlink" title="3.模型训练"></a>3.模型训练</h2><p>自编码网路结构采用（784，128,64,10,10,64，128,684）的结构进行无监督训练。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">nput_img&#x3D;Input(shape&#x3D;(784,))</span><br><span class="line"># 编码层</span><br><span class="line">encoded&#x3D;Dense(128,activation&#x3D;&#39;relu&#39;,name&#x3D;&#39;encoded_hidden1&#39;)(input_img)</span><br><span class="line">encoder_output&#x3D;Dense(64,activation&#x3D;&#39;relu&#39;,name&#x3D;&#39;encoded_hidden2&#39;)(encoded)</span><br><span class="line">LR&#x3D;Dense(10,activation&#x3D;&#39;softmax&#39;,name&#x3D;&#39;LR&#39;)(encoder_output)</span><br><span class="line"></span><br><span class="line"># 解码层</span><br><span class="line">decoded&#x3D;Dense(64,activation&#x3D;&#39;relu&#39;,name&#x3D;&#39;decoded_hidden2&#39;)(encoder_output)</span><br><span class="line">decoded&#x3D;Dense(128,activation&#x3D;&#39;relu&#39;,name&#x3D;&#39;decoded_hidden3&#39;)(decoded)</span><br><span class="line">decoded&#x3D;Dense(784,activation&#x3D;&#39;tanh&#39;,name&#x3D;&#39;decoded_output&#39;)(decoded)</span><br><span class="line"></span><br><span class="line"># 构建自编码模型</span><br><span class="line">autoencoder&#x3D;Model(inputs&#x3D;input_img,outputs&#x3D;decoded)</span><br><span class="line"></span><br><span class="line"># complile autoencoder 设置自编码的优化参数</span><br><span class="line">autoencoder.compile(optimizer&#x3D;&#39;adam&#39;,loss&#x3D;&#39;mse&#39;)</span><br><span class="line"># train</span><br><span class="line">hist&#x3D;autoencoder.fit(X_train,X_train,epochs&#x3D;20,batch_size&#x3D;250,shuffle&#x3D;True)</span><br></pre></td></tr></table></figure>
<p>中间设置一个LR层，进行后面的多分类输出层。<br>下面是多分类的模型训练过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">采用编码层的网络结构，从新构成一个新的model，此model的参数跟原来autoencode的训练的参数一样。</span><br><span class="line">encoder&#x3D;Model(inputs&#x3D;input_img,outputs&#x3D;LR)</span><br><span class="line">encoder.compile(optimizer&#x3D;&#39;adam&#39;,loss&#x3D;&#39;categorical_crossentropy&#39;,metrics&#x3D;[&#39;categorical_accuracy&#39;])</span><br><span class="line">encoder.fit(X_train,y_train_cate,epochs&#x3D;20,batch_size&#x3D;250,shuffle&#x3D;True)</span><br><span class="line">core&#x3D;encoder.evaluate(X_test,y_test_cate)</span><br><span class="line">print(score)</span><br><span class="line">print(encoder.summary())</span><br></pre></td></tr></table></figure>
<p>评估结果与网络参数如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">score:</span><br><span class="line">[0.09663939199754969, 0.9704]</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">input_1 (InputLayer)         (None, 784)               0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">encoded_hidden1 (Dense)      (None, 128)               100480    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">encoded_hidden2 (Dense)      (None, 64)                8256      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">LR (Dense)                   (None, 10)                650       </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 109,386</span><br><span class="line">Trainable params: 109,386</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure>
<p>可以看出准确率与loss都很好。<br>参考链接：<br><a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a><br><a href="https://www.cnblogs.com/wzdLY/p/9683657.html" target="_blank" rel="noopener">https://www.cnblogs.com/wzdLY/p/9683657.html</a><br><a href="https://blog.csdn.net/simple_the_best/article/details/75267863" target="_blank" rel="noopener">https://blog.csdn.net/simple_the_best/article/details/75267863</a><br><a href="https://blog.csdn.net/hjimce/article/details/49106869" target="_blank" rel="noopener">https://blog.csdn.net/hjimce/article/details/49106869</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">julianxu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://snail110.github.io/2020/04/23/%E9%87%87%E7%94%A8Keras%20%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88SAE%EF%BC%89%E5%AE%9E%E7%8E%B0Mnist%E7%9A%84%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">http://snail110.github.io/2020/04/23/%E9%87%87%E7%94%A8Keras%20%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88SAE%EF%BC%89%E5%AE%9E%E7%8E%B0Mnist%E7%9A%84%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Snail110.github.io" target="_blank">一碗竹叶青</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DNN/">DNN</a><a class="post-meta__tags" href="/tags/Keras/">Keras</a></div><div class="post_share"><div class="social-share" data-image="http://img.ylq.com/2017/0316/20170316035833715.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/23/Linux%E5%AE%89%E8%A3%85%20Anaconda%E3%80%81Tensorflow-GPU%E3%80%81Keras%E3%80%81pytorch-gpu%E8%BF%87%E7%A8%8B/"><img class="prev_cover lazyload" data-src="http://img.ylq.com/2017/0316/20170316035833715.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">linux安装anaconda</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/23/Wide&amp;Deep%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"><img class="next_cover lazyload" data-src="http://dingyue.ws.126.net/lyFlfhBGdx8qHeO6nyMzTbcAXTuKFhbUwrsoh8WgxCWQX1579239824693compressflag.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Wide&amp;Deep</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/23/Deep Neural Network for YouTube Recommendation/" title="YouTube视频推荐的DNN算法"><img class="relatedPosts_cover lazyload"data-src="http://pic1.win4000.com/pic/3/3d/e0aa891379.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-23</div><div class="relatedPosts_title">YouTube视频推荐的DNN算法</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/DCN模型理论和实践/" title="DCN模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122154S0230.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">DCN模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/NFM/" title="NFM模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122155022A0.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">NFM模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/MLR/" title="MLR模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122154305S5.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">MLR模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/PNN模型理论和实践/" title="PNN模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122154525A5.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">PNN模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/23/Wide&Deep模型网络结构/" title="Wide&Deep"><img class="relatedPosts_cover lazyload"data-src="http://dingyue.ws.126.net/lyFlfhBGdx8qHeO6nyMzTbcAXTuKFhbUwrsoh8WgxCWQX1579239824693compressflag.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-23</div><div class="relatedPosts_title">Wide&Deep</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '5f0d5e0bdf7f8aeaaf56',
  clientSecret: 'dcdb00026cec17a372afde717c5b943294207dbf',
  repo: '',
  owner: '',
  admin: [''],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By julianxu</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">2</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>