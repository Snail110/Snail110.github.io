<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Wide&amp;Deep | 一碗竹叶青</title><meta name="description" content="Wide&amp;Deep"><meta name="keywords" content="推荐系统,DNN"><meta name="author" content="julianxu"><meta name="copyright" content="julianxu"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Wide&amp;Deep"><meta name="twitter:description" content="Wide&amp;Deep"><meta name="twitter:image" content="http://dingyue.ws.126.net/lyFlfhBGdx8qHeO6nyMzTbcAXTuKFhbUwrsoh8WgxCWQX1579239824693compressflag.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="Wide&amp;Deep"><meta property="og:url" content="http://snail110.github.io/2020/04/23/Wide&amp;Deep%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"><meta property="og:site_name" content="一碗竹叶青"><meta property="og:description" content="Wide&amp;Deep"><meta property="og:image" content="http://dingyue.ws.126.net/lyFlfhBGdx8qHeO6nyMzTbcAXTuKFhbUwrsoh8WgxCWQX1579239824693compressflag.jpeg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://snail110.github.io/2020/04/23/Wide&amp;Deep%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"><link rel="prev" title="堆栈式自编码器" href="http://snail110.github.io/2020/04/23/%E9%87%87%E7%94%A8Keras%20%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88SAE%EF%BC%89%E5%AE%9E%E7%8E%B0Mnist%E7%9A%84%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"><link rel="next" title="YouTube视频推荐的DNN算法" href="http://snail110.github.io/2020/04/23/Deep%20Neural%20Network%20for%20YouTube%20Recommendation/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5/js/md5.min.js"></script><script src="https://tajs.qq.com/stats?sId=66547258" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/user.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 档案室</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/playlist/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#概述"><span class="toc-number">1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#0-介绍"><span class="toc-number">2.</span> <span class="toc-text">0.介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-网络结构"><span class="toc-number">3.</span> <span class="toc-text">1.网络结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#公式（1）"><span class="toc-number">3.1.</span> <span class="toc-text">公式（1）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#公式（2）"><span class="toc-number">3.2.</span> <span class="toc-text">公式（2）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#公式（3）"><span class="toc-number">3.3.</span> <span class="toc-text">公式（3）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-代码复现"><span class="toc-number">4.</span> <span class="toc-text">2.代码复现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Wide-Layers"><span class="toc-number">4.1.</span> <span class="toc-text">Wide Layers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Layers"><span class="toc-number">4.2.</span> <span class="toc-text">Deep Layers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Concatenate-layer"><span class="toc-number">4.3.</span> <span class="toc-text">Concatenate layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Train"><span class="toc-number">4.4.</span> <span class="toc-text">Train</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-总结"><span class="toc-number">5.</span> <span class="toc-text">3.总结</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(http://dingyue.ws.126.net/lyFlfhBGdx8qHeO6nyMzTbcAXTuKFhbUwrsoh8WgxCWQX1579239824693compressflag.jpeg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">一碗竹叶青</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 档案室</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/playlist/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Wide&amp;Deep</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-23 08:55:45"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-23</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-04-23 09:11:58"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-04-23</span></time></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/23/Wide&amp;Deep%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><meta name="referrer" content="no-referrer">

<p>参考文章：<br>1、<a href="https://github.com/brightnesss/deep-cross/blob/master/CDNet.py" target="_blank" rel="noopener">https://github.com/brightnesss/deep-cross/blob/master/CDNet.py</a><br>2、<a href="https://zhuanlan.zhihu.com/p/92279796" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/92279796</a></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>该系列主要是复现一些经典的网络结构与顶会论文的网络结构，我一开始看论文，以为看到网络结构和了解结构原理后，就完全学到了这篇论文的精髓，谁知，等到自己想要用这个网络结构时，无法打通理解与代码复现的这一步，这就导致我在科研或者工作时的束手无措，因此，我就决定探究如何将一篇论文中的结构和论文中的公式用代码的形式复现出来。<br>深度学习框架：tensorflow2.0 ，numpy。<br>语言：python。<br>复现的代码全部在：<a href="https://github.com/Snail110/recsys。" target="_blank" rel="noopener">https://github.com/Snail110/recsys。</a></p>
<h2 id="0-介绍"><a href="#0-介绍" class="headerlink" title="0.介绍"></a>0.介绍</h2><p>2016年，Google提出Wide&amp;Deep模型，将线性模型与DNN很好的结合起来，在提高模型泛化能力的同时，兼顾模型的记忆性。Wide&amp;Deep这种线性模型与DNN的并行连接模式，后来成为推荐领域的经典模式。</p>
<h2 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1.网络结构"></a>1.网络结构</h2><p>该部分主要是将论文中公式与结构图对应起来，理解每一个公式的含义以及网络结构图中每一部分的输入输出。<br><img src="/" class="lazyload" data-src="https://img-blog.csdnimg.cn/202001071701000.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhaWR1XzM4MTI3MTYy,size_16,color_FFFFFF,t_70"  alt="在这里插入图片描述"><br>首先，当你看完一篇论文并理解了论文的主要思想后，需要尝试着将网络结构与论文中的每一步的数学公式一一对应上，在心中或者图片上协商每一个环节的数学公式，然后考虑用深度学习框架来实现。<br>首先这篇论文中有数学公式(1)，（2）,（3）对应着网络模型。<br>然后需要一步一步的将公式对应到网络模型中，</p>
<h3 id="公式（1）"><a href="#公式（1）" class="headerlink" title="公式（1）"></a>公式（1）</h3><p><img src="/" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200107170121117.PNG"  alt="在这里插入图片描述"><br>wide部分输入时x = [x1; x2; :::; xd]，输出是y，在这里需要注意的是交叉特征的构建，即公式1，因此在数据特征准备时，需要进行交叉特征的构建。</p>
<h3 id="公式（2）"><a href="#公式（2）" class="headerlink" title="公式（2）"></a>公式（2）</h3><p><img src="/" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200107170134565.PNG"  alt="在这里插入图片描述"><br>公式2中表示将embedding的向量与稠密向量拼接在一起后，Deep部分的网络结构</p>
<h3 id="公式（3）"><a href="#公式（3）" class="headerlink" title="公式（3）"></a>公式（3）</h3><p><img src="/" class="lazyload" data-src="https://img-blog.csdnimg.cn/202001071701479.PNG"  alt="在这里插入图片描述"><br>这个公式是两部分的拼接过程。最终输出概率值。</p>
<h2 id="2-代码复现"><a href="#2-代码复现" class="headerlink" title="2.代码复现"></a>2.代码复现</h2><p>该部分主要是按照网络结构图，用代码的方式实现。在代码实现的过程中，我们需要紧紧结合数学公式体会其中的含义以及如何用代码来实现这些数学公式。<br>我是基于数据集：<a href="https://www.kaggle.com/c/porto-seguro-safe-driver-prediction来实现的。" target="_blank" rel="noopener">https://www.kaggle.com/c/porto-seguro-safe-driver-prediction来实现的。</a></p>
<h3 id="Wide-Layers"><a href="#Wide-Layers" class="headerlink" title="Wide Layers"></a>Wide Layers</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Wide</span><span class="params">(tf.keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,units=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># input_dim = num_size + embed_size = input_size</span></span><br><span class="line">        super(Wide, self).__init__()</span><br><span class="line"><span class="comment">#         self.units = units</span></span><br><span class="line">        self.linear = tf.keras.layers.Dense(units=units,activation=<span class="string">'relu'</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        output = self.linear(inputs)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="Deep-Layers"><a href="#Deep-Layers" class="headerlink" title="Deep Layers"></a>Deep Layers</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Deep</span><span class="params">(tf.keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,num_feat,num_field,dropout_deep,deep_layer_sizes,embedding_size=<span class="number">10</span>)</span>:</span></span><br><span class="line">        <span class="comment"># input_dim = num_size + embed_size = input_size</span></span><br><span class="line">        super(Deep, self).__init__()</span><br><span class="line">        self.num_feat = num_feat <span class="comment"># F =features nums</span></span><br><span class="line">        self.num_field = num_field <span class="comment"># N =fields of a feature </span></span><br><span class="line">        self.dropout_deep  = dropout_deep</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Embedding 这里采用embeddings层因此大小为F* M F为特征数量，M为embedding的维度</span></span><br><span class="line">        feat_embeddings = tf.keras.layers.Embedding(num_feat, embedding_size, embeddings_initializer=<span class="string">'uniform'</span>) <span class="comment"># F * M </span></span><br><span class="line">        self.feat_embeddings = feat_embeddings</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># fc layer</span></span><br><span class="line">        self.deep_layer_sizes = deep_layer_sizes</span><br><span class="line">        <span class="comment">#神经网络方面的参数</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(deep_layer_sizes)):</span><br><span class="line">            setattr(self, <span class="string">'dense_'</span> + str(i),tf.keras.layers.Dense(deep_layer_sizes[i]))</span><br><span class="line">            setattr(self, <span class="string">'batchNorm_'</span> + str(i),tf.keras.layers.BatchNormalization())</span><br><span class="line">            setattr(self, <span class="string">'activation_'</span> + str(i),tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">            setattr(self, <span class="string">'dropout_'</span> + str(i),tf.keras.layers.Dropout(dropout_deep[i]))</span><br><span class="line">        <span class="comment"># last layer</span></span><br><span class="line">        self.fc = tf.keras.layers.Dense(<span class="number">1</span>,activation=<span class="literal">None</span>,use_bias=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,feat_index,feat_value)</span>:</span></span><br><span class="line">        <span class="comment"># embedding part  feat_index = inputs为输入 feat_embeddings为一个layer。</span></span><br><span class="line">        feat_embedding_0 = self.feat_embeddings(feat_index) <span class="comment"># Batch * N * M </span></span><br><span class="line"><span class="comment">#         print(feat_value.get_shape())</span></span><br><span class="line">        feat_embedding = tf.einsum(<span class="string">'bnm,bn-&gt;bnm'</span>,feat_embedding_0,feat_value)</span><br><span class="line"></span><br><span class="line">        y_deep = tf.keras.layers.Flatten()(feat_embedding)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.deep_layer_sizes)):</span><br><span class="line">            y_deep = getattr(self,<span class="string">'dense_'</span> + str(i))(y_deep)</span><br><span class="line">            y_deep = getattr(self,<span class="string">'batchNorm_'</span> + str(i))(y_deep)</span><br><span class="line">            y_deep = getattr(self,<span class="string">'activation_'</span> + str(i))(y_deep)</span><br><span class="line">            y_deep = getattr(self,<span class="string">'dropout_'</span> + str(i))(y_deep)</span><br><span class="line">        </span><br><span class="line">        output = self.fc(y_deep)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="Concatenate-layer"><a href="#Concatenate-layer" class="headerlink" title="Concatenate layer"></a>Concatenate layer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WideDeep</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,num_feat,num_field,dropout_deep,deep_layer_sizes,embedding_size=<span class="number">10</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.num_feat = num_feat <span class="comment"># F =features nums</span></span><br><span class="line">        self.num_field = num_field <span class="comment"># N =fields of a feature </span></span><br><span class="line">        self.dropout_deep  = dropout_deep</span><br><span class="line">        </span><br><span class="line">        self.wide = Wide(units=<span class="number">1</span>)</span><br><span class="line">        self.deep = Deep(num_feat,num_field,dropout_deep,deep_layer_sizes)</span><br><span class="line">        self.fc = tf.keras.layers.Dense(<span class="number">1</span>,activation=<span class="literal">None</span>,use_bias=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,num_input,feat_index,feat_value)</span>:</span></span><br><span class="line">        x1 = self.wide(num_input)</span><br><span class="line">        x2 = self.deep(feat_index,feat_value)</span><br><span class="line">        </span><br><span class="line">        x3 = tf.keras.layers.concatenate([x1,x2],axis=<span class="number">-1</span>)</span><br><span class="line">        output = self.fc(x3)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">AID_DATA_DIR = <span class="string">"../data/Criteo/"</span></span><br><span class="line">feat_dict_ = pickle.load(open(AID_DATA_DIR + <span class="string">'/cross_feat_dict_10.pkl2'</span>, <span class="string">'rb'</span>))</span><br><span class="line"></span><br><span class="line">widedeep = WideDeep(num_feat=len(feat_dict_) + <span class="number">1</span>, num_field=<span class="number">52</span>, dropout_deep=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>],</span><br><span class="line">                deep_layer_sizes=[<span class="number">400</span>, <span class="number">400</span>],embedding_size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">train_label_path = AID_DATA_DIR + <span class="string">'traincross_label'</span></span><br><span class="line">train_idx_path = AID_DATA_DIR + <span class="string">'traincross_idx'</span></span><br><span class="line">train_value_path = AID_DATA_DIR + <span class="string">'traincross_value'</span></span><br><span class="line">train_num_path = AID_DATA_DIR + <span class="string">'traincross_num'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这种读取数据方式采用TextLineDataset，数据为大文件时，节省内存，效率训练</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_dataset</span><span class="params">(label_path, idx_path, value_path,num_path)</span>:</span></span><br><span class="line">    label = tf.data.TextLineDataset(label_path)</span><br><span class="line">    idx = tf.data.TextLineDataset(idx_path)</span><br><span class="line">    value = tf.data.TextLineDataset(value_path)</span><br><span class="line">    num = tf.data.TextLineDataset(num_path)</span><br><span class="line"></span><br><span class="line">    label = label.map(<span class="keyword">lambda</span> x: tf.strings.to_number(tf.strings.split(x, sep=<span class="string">'\t'</span>)), num_parallel_calls=<span class="number">12</span>)</span><br><span class="line">    idx = idx.map(<span class="keyword">lambda</span> x: tf.strings.to_number(tf.strings.split(x, sep=<span class="string">'\t'</span>)), num_parallel_calls=<span class="number">12</span>)</span><br><span class="line">    value = value.map(<span class="keyword">lambda</span> x: tf.strings.to_number(tf.strings.split(x, sep=<span class="string">'\t'</span>)), num_parallel_calls=<span class="number">12</span>)</span><br><span class="line">    num = num.map(<span class="keyword">lambda</span> x: tf.strings.to_number(tf.strings.split(x, sep=<span class="string">'\t'</span>)), num_parallel_calls=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">    batch_dataset = tf.data.Dataset.zip((num,label, idx, value))</span><br><span class="line">    batch_dataset = batch_dataset.shuffle(buffer_size=<span class="number">128</span>)</span><br><span class="line">    batch_dataset = batch_dataset.batch(<span class="number">128</span>)</span><br><span class="line">    batch_dataset = batch_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)</span><br><span class="line">    <span class="keyword">return</span> batch_dataset</span><br><span class="line">train_batch_dataset = get_batch_dataset(train_label_path, train_idx_path, train_value_path,train_num_path)</span><br><span class="line"></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.BinaryAccuracy(name=<span class="string">'train_acc'</span>)</span><br><span class="line">loss_object = tf.keras.losses.BinaryCrossentropy()</span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_one_step</span><span class="params">(model, optimizer, idx, value, label, num)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        output = model(num, idx, value)</span><br><span class="line">        loss = loss_object(y_true=label, y_pred=output)</span><br><span class="line">    grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    grads = [tf.clip_by_norm(g, <span class="number">100</span>) <span class="keyword">for</span> g <span class="keyword">in</span> grads]</span><br><span class="line">    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">    train_loss(loss)</span><br><span class="line">    train_accuracy(label, output)</span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">50</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> num, label, idx, value <span class="keyword">in</span> train_batch_dataset:</span><br><span class="line">        train_one_step(widedeep, optimizer, idx, value, label,num)</span><br><span class="line">    template = <span class="string">'Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;'</span></span><br><span class="line">    print(template.format(epoch + <span class="number">1</span>,</span><br><span class="line">                          train_loss.result(), train_accuracy.result()))</span><br></pre></td></tr></table></figure>

<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h2><p>你看，通过这样一步步将公式与代码对应起来，就好实现多了，对于不同的计算公式采用不同的函数需要多看文档，这样才可以选用正确的api。<br>最后，如果需要获取全部代码，请看下我的github上仓库：<a href="https://github.com/Snail110/recsys" target="_blank" rel="noopener">https://github.com/Snail110/recsys</a></p>
<p>这里面是用tensorflow2.0框架来写。如果觉得我实现的还不错，记得给我一个星星哦。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">julianxu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://snail110.github.io/2020/04/23/Wide&amp;Deep%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/">http://snail110.github.io/2020/04/23/Wide&amp;Deep%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Snail110.github.io" target="_blank">一碗竹叶青</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a><a class="post-meta__tags" href="/tags/DNN/">DNN</a></div><div class="post_share"><div class="social-share" data-image="http://img.ylq.com/2017/0316/20170316035833715.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/23/%E9%87%87%E7%94%A8Keras%20%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%88SAE%EF%BC%89%E5%AE%9E%E7%8E%B0Mnist%E7%9A%84%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"><img class="prev_cover lazyload" data-src="http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190502/3a0df3c1cd0a48d6abb30bc0e3698fe0.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">堆栈式自编码器</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/23/Deep%20Neural%20Network%20for%20YouTube%20Recommendation/"><img class="next_cover lazyload" data-src="http://pic1.win4000.com/wallpaper/c/5970415315af0.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">YouTube视频推荐的DNN算法</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/23/Deep Neural Network for YouTube Recommendation/" title="YouTube视频推荐的DNN算法"><img class="relatedPosts_cover lazyload"data-src="http://pic1.win4000.com/wallpaper/c/5970415315af0.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-23</div><div class="relatedPosts_title">YouTube视频推荐的DNN算法</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/DCN模型理论和实践/" title="DCN模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122154S0230.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">DCN模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/GBDT+LR算法解析/" title="GBDT+LR模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122154Z2Z9.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">GBDT+LR模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/MLR/" title="MLR模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122154305S5.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">MLR模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/PNN模型理论和实践/" title="PNN模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122154525A5.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">PNN模型理论和实践</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/22/NFM/" title="NFM模型理论和实践"><img class="relatedPosts_cover lazyload"data-src="https://img.phb123.com/uploads/allimg/180122/24-1P122155022A0.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-22</div><div class="relatedPosts_title">NFM模型理论和实践</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '5f0d5e0bdf7f8aeaaf56',
  clientSecret: 'dcdb00026cec17a372afde717c5b943294207dbf',
  repo: '',
  owner: '',
  admin: [''],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By julianxu</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">2</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>